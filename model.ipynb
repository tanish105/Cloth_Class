{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_dataset = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train) , (x_test, y_test) = fashion_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b27fc17390>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[100], cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "img_row = x_train[0].shape[0]\n",
    "img_column = x_train[1].shape[0]\n",
    "\n",
    "#change shape to (60000,28,28,1)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], img_row, img_column, 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], img_row, img_column, 1))\n",
    "\n",
    "#normalize the data\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "#one hot encoding\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_test.shape[1]\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3),activation='relu', input_shape=(img_row, img_column, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,200,778\n",
      "Trainable params: 1,200,330\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 69s 142ms/step - loss: 0.4362 - accuracy: 0.8481 - val_loss: 4.5084 - val_accuracy: 0.3676\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 79s 168ms/step - loss: 0.2813 - accuracy: 0.8998 - val_loss: 0.2864 - val_accuracy: 0.8955\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 79s 168ms/step - loss: 0.2345 - accuracy: 0.9163 - val_loss: 0.2429 - val_accuracy: 0.9136\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 80s 172ms/step - loss: 0.2048 - accuracy: 0.9268 - val_loss: 0.2192 - val_accuracy: 0.9199\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 81s 173ms/step - loss: 0.1856 - accuracy: 0.9321 - val_loss: 0.2466 - val_accuracy: 0.9130\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 83s 176ms/step - loss: 0.1660 - accuracy: 0.9386 - val_loss: 0.2181 - val_accuracy: 0.9245\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 82s 175ms/step - loss: 0.1537 - accuracy: 0.9445 - val_loss: 0.2363 - val_accuracy: 0.9189\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 82s 175ms/step - loss: 0.1370 - accuracy: 0.9502 - val_loss: 0.2193 - val_accuracy: 0.9256\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 101s 215ms/step - loss: 0.1250 - accuracy: 0.9546 - val_loss: 0.2276 - val_accuracy: 0.9230\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 91s 193ms/step - loss: 0.1199 - accuracy: 0.9555 - val_loss: 0.2168 - val_accuracy: 0.9268\n",
      "Test loss: 0.2168215811252594\n",
      "Test accuracy: 0.926800012588501\n"
     ]
    }
   ],
   "source": [
    "#train the model\n",
    "model_train = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('clothing_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 155ms/step\n",
      "8\n",
      "The predicted apparel category is: Bag\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "\n",
    "def load_image(filename):\n",
    "    img = load_img(filename, color_mode='grayscale', target_size=(28, 28))\n",
    "    img = img_to_array(img)\n",
    "    img = img.reshape(1, 28, 28, 1)\n",
    "    img = img.astype('float32')\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = load_image('sneaker.jpg')\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = load_model('clothing_classification.h5')\n",
    "\n",
    "# Predict the class\n",
    "class_prediction = np.argmax(model.predict(img), axis=-1)\n",
    "predicted_class = class_prediction[0]\n",
    "print(predicted_class)\n",
    "\n",
    "# Map apparel category with the numerical class\n",
    "if predicted_class == 0:\n",
    "    product = \"T-shirt/top\"\n",
    "elif predicted_class == 1:\n",
    "    product = \"Trouser\"\n",
    "elif predicted_class == 2:\n",
    "    product = \"Pullover\"\n",
    "elif predicted_class == 3:\n",
    "    product = \"Dress\"\n",
    "elif predicted_class == 4:\n",
    "    product = \"Coat\"\n",
    "elif predicted_class == 5:\n",
    "    product = \"Sandal\"\n",
    "elif predicted_class == 6:\n",
    "    product = \"Shirt\"\n",
    "elif predicted_class == 7:\n",
    "    product = \"Sneaker\"\n",
    "elif predicted_class == 8:\n",
    "    product = \"Bag\"\n",
    "else:\n",
    "    product = \"Ankle boot\"\n",
    "\n",
    "print(f'The predicted apparel category is: {product}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'clothing_classification.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
